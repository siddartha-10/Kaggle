{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5de71eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_essays = pd.read_csv('train_essays.csv')\n",
    "test_essays = pd.read_csv('test_essays.csv')\n",
    "train_prompts = pd.read_csv('train_prompts.csv')\n",
    "\n",
    "# Merge training essays and prompts based on prompt_id\n",
    "train_data = train_essays.merge(train_prompts, on='prompt_id')\n",
    "\n",
    "# Check for missing data\n",
    "train_data.isnull().sum()  # Check for missing values in the merged dataset\n",
    "train_data.dropna(subset=['text'], inplace=True)  # Remove rows with missing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "677e7854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text   \n",
       "0  0059830c          0  Cars. Cars have been around since they became ...  \\\n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "\n",
       "   generated      prompt_name   \n",
       "0          0  Car-free cities  \\\n",
       "1          0  Car-free cities   \n",
       "2          0  Car-free cities   \n",
       "3          0  Car-free cities   \n",
       "4          0  Car-free cities   \n",
       "\n",
       "                                        instructions   \n",
       "0  Write an explanatory essay to inform fellow ci...  \\\n",
       "1  Write an explanatory essay to inform fellow ci...   \n",
       "2  Write an explanatory essay to inform fellow ci...   \n",
       "3  Write an explanatory essay to inform fellow ci...   \n",
       "4  Write an explanatory essay to inform fellow ci...   \n",
       "\n",
       "                                         source_text  \n",
       "0  # In German Suburb, Life Goes On Without Cars ...  \n",
       "1  # In German Suburb, Life Goes On Without Cars ...  \n",
       "2  # In German Suburb, Life Goes On Without Cars ...  \n",
       "3  # In German Suburb, Life Goes On Without Cars ...  \n",
       "4  # In German Suburb, Life Goes On Without Cars ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477c8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07e0e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d66b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ex = tokenizer([\"Cars. Cars have been around since they became\",\n",
    "                         \"what is your name\"],\n",
    "                         max_length=1000,padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d483afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101, 3765, 1012, 3765, 2031, 2042, 2105, 2144, 2027, 2150, 102], [101, 2054, 2003, 2115, 2171, 102, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_ex.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e588ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    tokens_input = tokenizer(data,max_length=1000,padding=True,truncation=True)\n",
    "    return tokens_input.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba289899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text_tokenize'] = train_data['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "526e3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['prompt_name_tokenize'] = train_data['prompt_name'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7327c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['instructions_tokenize'] = train_data['instructions'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6007c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['source_text_tokenize'] = train_data['source_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c99322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>prompt_name_tokenize</th>\n",
       "      <th>instructions_tokenize</th>\n",
       "      <th>source_text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "      <td>[101, 3765, 1012, 3765, 2031, 2042, 2105, 2144...</td>\n",
       "      <td>[101, 2482, 1011, 2489, 3655, 102]</td>\n",
       "      <td>[101, 4339, 2019, 4654, 24759, 5162, 7062, 949...</td>\n",
       "      <td>[101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "      <td>[101, 5193, 2003, 1037, 2312, 13185, 1999, 208...</td>\n",
       "      <td>[101, 2482, 1011, 2489, 3655, 102]</td>\n",
       "      <td>[101, 4339, 2019, 4654, 24759, 5162, 7062, 949...</td>\n",
       "      <td>[101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "      <td>[101, 1000, 2637, 1005, 1055, 2293, 6771, 2007...</td>\n",
       "      <td>[101, 2482, 1011, 2489, 3655, 102]</td>\n",
       "      <td>[101, 4339, 2019, 4654, 24759, 5162, 7062, 949...</td>\n",
       "      <td>[101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "      <td>[101, 2129, 2411, 2079, 2017, 4536, 1999, 1037...</td>\n",
       "      <td>[101, 2482, 1011, 2489, 3655, 102]</td>\n",
       "      <td>[101, 4339, 2019, 4654, 24759, 5162, 7062, 949...</td>\n",
       "      <td>[101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "      <td>[101, 3765, 2024, 1037, 6919, 2518, 1012, 2027...</td>\n",
       "      <td>[101, 2482, 1011, 2489, 3655, 102]</td>\n",
       "      <td>[101, 4339, 2019, 4654, 24759, 5162, 7062, 949...</td>\n",
       "      <td>[101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text   \n",
       "0  0059830c          0  Cars. Cars have been around since they became ...  \\\n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "\n",
       "   generated      prompt_name   \n",
       "0          0  Car-free cities  \\\n",
       "1          0  Car-free cities   \n",
       "2          0  Car-free cities   \n",
       "3          0  Car-free cities   \n",
       "4          0  Car-free cities   \n",
       "\n",
       "                                        instructions   \n",
       "0  Write an explanatory essay to inform fellow ci...  \\\n",
       "1  Write an explanatory essay to inform fellow ci...   \n",
       "2  Write an explanatory essay to inform fellow ci...   \n",
       "3  Write an explanatory essay to inform fellow ci...   \n",
       "4  Write an explanatory essay to inform fellow ci...   \n",
       "\n",
       "                                         source_text   \n",
       "0  # In German Suburb, Life Goes On Without Cars ...  \\\n",
       "1  # In German Suburb, Life Goes On Without Cars ...   \n",
       "2  # In German Suburb, Life Goes On Without Cars ...   \n",
       "3  # In German Suburb, Life Goes On Without Cars ...   \n",
       "4  # In German Suburb, Life Goes On Without Cars ...   \n",
       "\n",
       "                                       text_tokenize   \n",
       "0  [101, 3765, 1012, 3765, 2031, 2042, 2105, 2144...  \\\n",
       "1  [101, 5193, 2003, 1037, 2312, 13185, 1999, 208...   \n",
       "2  [101, 1000, 2637, 1005, 1055, 2293, 6771, 2007...   \n",
       "3  [101, 2129, 2411, 2079, 2017, 4536, 1999, 1037...   \n",
       "4  [101, 3765, 2024, 1037, 6919, 2518, 1012, 2027...   \n",
       "\n",
       "                 prompt_name_tokenize   \n",
       "0  [101, 2482, 1011, 2489, 3655, 102]  \\\n",
       "1  [101, 2482, 1011, 2489, 3655, 102]   \n",
       "2  [101, 2482, 1011, 2489, 3655, 102]   \n",
       "3  [101, 2482, 1011, 2489, 3655, 102]   \n",
       "4  [101, 2482, 1011, 2489, 3655, 102]   \n",
       "\n",
       "                               instructions_tokenize   \n",
       "0  [101, 4339, 2019, 4654, 24759, 5162, 7062, 949...  \\\n",
       "1  [101, 4339, 2019, 4654, 24759, 5162, 7062, 949...   \n",
       "2  [101, 4339, 2019, 4654, 24759, 5162, 7062, 949...   \n",
       "3  [101, 4339, 2019, 4654, 24759, 5162, 7062, 949...   \n",
       "4  [101, 4339, 2019, 4654, 24759, 5162, 7062, 949...   \n",
       "\n",
       "                                source_text_tokenize  \n",
       "0  [101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...  \n",
       "1  [101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...  \n",
       "2  [101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...  \n",
       "3  [101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...  \n",
       "4  [101, 1001, 1999, 2446, 7575, 1010, 2166, 3632...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "387f22a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1378 entries, 0 to 1377\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     1378 non-null   object\n",
      " 1   prompt_id              1378 non-null   int64 \n",
      " 2   text                   1378 non-null   object\n",
      " 3   generated              1378 non-null   int64 \n",
      " 4   prompt_name            1378 non-null   object\n",
      " 5   instructions           1378 non-null   object\n",
      " 6   source_text            1378 non-null   object\n",
      " 7   text_tokenize          1378 non-null   object\n",
      " 8   prompt_name_tokenize   1378 non-null   object\n",
      " 9   instructions_tokenize  1378 non-null   object\n",
      " 10  source_text_tokenize   1378 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 118.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b315deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generated\n",
       "0    1375\n",
       "1       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['generated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "667843fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2698201068.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[47], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    train_data['id'] =\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_data['id'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8499a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report,confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f22f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['text','generated','prompt_name','instructions','source_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8adf4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=dropped_cols,axis=0)\n",
    "y = train_data['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2e173e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57da245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2937ba92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ss \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m()\n\u001b[1;32m      2\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39mfit_transform(x_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba8f3888",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '945de5f3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:1998\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1997\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1998\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2000\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   2001\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   2002\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[1;32m   2003\u001b[0m     ):\n\u001b[1;32m   2004\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[1;32m   2006\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   2007\u001b[0m         ):\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '945de5f3'"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_prob = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    pr_auc = average_precision_score(y_test, y_prob)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Create a PrettyTable for the classification report\n",
    "    report_table = PrettyTable()\n",
    "    report_table.field_names = ['Class', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "    for class_name, metrics in cr.items():\n",
    "        if class_name.isdigit():  # Skip non-numeric class names (if any)\n",
    "            report_table.add_row([class_name,\n",
    "                                  metrics['precision'],\n",
    "                                  metrics['recall'],\n",
    "                                  metrics['f1-score'],\n",
    "                                  metrics['support']])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Confusion matrix:\\n{cm}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Classification report:\")\n",
    "    print(report_table)\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    print(f\"PR AUC: {pr_auc:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Accuracy :{accuracy}\")\n",
    "    print(f\"Precision :{precision}\")\n",
    "    print(f\"recall :{recall}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e5b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform test data using the same TF-IDF vectorizer\n",
    "# X_test = tfidf_vectorizer.transform(test_essays['text'])\n",
    "\n",
    "# # Use the trained model to predict on the test data\n",
    "# test_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# # Prepare for submission\n",
    "# submission = pd.DataFrame({'id': test_essays['id'], 'generated': test_predictions})\n",
    "\n",
    "# # Save the submission to a CSV file\n",
    "# submission.to_csv('essay_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9c4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
